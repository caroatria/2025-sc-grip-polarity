{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for the analysis  and visualistion of sc-GRIP predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    adjusted_rand_score,\n",
    "    normalized_mutual_info_score,\n",
    "    roc_curve,\n",
    "    auc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating necessary files from published datasets #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read in adjacency matrix ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = \"mouse\"\n",
    "celltype = \"muscle\"\n",
    "\n",
    "df = pd.read_csv(\"data/trrust_rawdata.\"+species+\".tsv\",sep=\"\\t\",header=None,names=[\"gene_ids\",\"target_genes\",\"polarity\",\"val\"])\n",
    "\n",
    "filtered_subset_df = df[df[\"polarity\"] != \"Unknown\"]\n",
    "filtered_subset_df = filtered_subset_df.drop_duplicates(subset=[\"gene_ids\",\"target_genes\"],keep=False)\n",
    "\n",
    "subset_df =filtered_subset_df[[\"gene_ids\",\"target_genes\",\"polarity\"]]\n",
    "\n",
    "gene_counts = df['target_genes'].value_counts()\n",
    "tf_counts = df['gene_ids'].value_counts()\n",
    "adj_matrix = pd.crosstab(subset_df[\"gene_ids\"], subset_df[\"target_genes\"])\n",
    "\n",
    "adj_matrix = (adj_matrix > 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read in single-cell matrix ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(\"data/h5ad_files/\"+species+\"_\"+celltype+\".h5ad\")\n",
    "\n",
    "#depending on the mumber of genes you might have to filter for highly variable genes\n",
    "sc.pp.highly_variable_genes(adata, flavor='seurat')\n",
    "adata = adata[:, adata.var['highly_variable']].copy()\n",
    "\n",
    "\n",
    "#depending on the adata.X datatype, chose the corresponding line to comment out\n",
    "data = adata.X.toarray()\n",
    "# data =adata.X\n",
    "\n",
    "expr_df = pd.DataFrame(data=data, columns=adata.var_names,index=adata.obs_names.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_df = adj_matrix\n",
    "\n",
    "tf_list = edge_df.index.to_list()\n",
    "target_gene_list = edge_df.columns.to_list()\n",
    "all_interacting_genes = tf_list + target_gene_list\n",
    "common_genes = list(set(expr_df.columns.to_list()) & set(all_interacting_genes))\n",
    "common_target_genes = list(set(expr_df.columns.to_list()) & set(target_gene_list))\n",
    "common_tf_genes = list(set(expr_df.columns.to_list()) & set(tf_list))\n",
    "all_common_genes = common_target_genes + common_tf_genes\n",
    "new_expr_df = expr_df[common_genes]\n",
    "new_edge_df = edge_df[common_target_genes]\n",
    "new_edge_df = new_edge_df.loc[common_tf_genes]\n",
    "\n",
    "expr_df = new_expr_df\n",
    "edge_df = new_edge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save files for later analyses ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cluster =str(celltype + \"_\")\n",
    "\n",
    "new_edge_df.to_csv(\"data/\"+species+\"_\"+target_cluster+\"tf_interaction_common.csv\")\n",
    "new_expr_df.to_csv(\"data/\"+species+\"_\"+target_cluster+\"gex_common.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison analyses #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson Correlation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gene_correlations(df_expr, df_adj):\n",
    "    data = []\n",
    "\n",
    "    for gene1 in df_adj.index:\n",
    "        for gene2 in df_adj.columns:\n",
    "            if df_adj.loc[gene1, gene2] == 1:\n",
    "                corr = np.corrcoef(df_expr[gene1], df_expr[gene2])[0, 1]\n",
    "                data.append({\n",
    "                    'TF': gene1,\n",
    "                    'target': gene2,\n",
    "                    'Correlation': corr\n",
    "                })\n",
    "\n",
    "    df_correlations = pd.DataFrame(data)\n",
    "    return df_correlations\n",
    "\n",
    "df_gene_correlations = compute_gene_correlations(new_expr_df,new_edge_df)\n",
    "df_gene_correlations['edge'] = df_gene_correlations['TF'] + \"->\" + df_gene_correlations['target']\n",
    "df_clean = df_gene_correlations.dropna()\n",
    "df_gene_correlations.to_csv(species+\"_\"+celltype+\"_correlations.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO edge weights ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def compute_lasso_scores(df_expr, df_adj, alpha=0.01):\n",
    "    data = []\n",
    "    scaler = StandardScaler()\n",
    "    df_expr_scaled = pd.DataFrame(scaler.fit_transform(df_expr), columns=df_expr.columns, index=df_expr.index)\n",
    "\n",
    "    for target_gene in df_adj.columns:  # target\n",
    "        tf_genes = df_adj.index[df_adj[target_gene] == 1].tolist()\n",
    "        if not tf_genes:\n",
    "            continue  # No TFs regulating this target gene\n",
    "\n",
    "        X = df_expr_scaled[tf_genes]\n",
    "        y = df_expr_scaled[target_gene]\n",
    "\n",
    "        lasso = Lasso(alpha=alpha, max_iter=10000)\n",
    "        lasso.fit(X, y)\n",
    "        coefs = lasso.coef_\n",
    "\n",
    "        for tf, coef in zip(tf_genes, coefs):\n",
    "            if coef != 0:\n",
    "                data.append({\n",
    "                    'TF': tf,\n",
    "                    'target': target_gene,\n",
    "                    'Lasso_Coefficient': coef\n",
    "                })\n",
    "\n",
    "    df_lasso = pd.DataFrame(data)\n",
    "    return df_lasso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising sc-GRIP predictions #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative analysis ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = \"mouse\"\n",
    "celltype = \"lung\"\n",
    "\n",
    "true_df = subset_df\n",
    "predicted_df = pd.read_csv(\"predictions/\"+species+\"_\"+celltype+\"_corr.csv\")\n",
    "true_df['edge'] = true_df['gene_ids'] + \"->\" + true_df['target_genes']\n",
    "df = pd.merge(true_df, predicted_df, on='edge', how='inner')\n",
    "col_label=\"activation_score_mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Activation\", \"Repression\"]\n",
    "\n",
    "label_map = {\"Activation\": 1, \"Repression\": 0,\"Unknown\":0.5}\n",
    "y_true_binary = df['polarity'].map(label_map)\n",
    "y_scores = df[col_label]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true_binary, y_scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(roc_auc)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='navy', lw=2,linestyle=\"solid\",label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--',label=\"Random chance (AUC=0.5)\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve ('+species+' dataset ('+celltype+\")\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualitative analysis ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import colors,cm\n",
    "\n",
    "\n",
    "def load_data(cluster_of_interest):\n",
    "    df = pd.read_csv(\"/species_predictions.csv\")\n",
    "    print(\"number of edges (raw)\", df.shape[0])\n",
    "    print(\"number of edges (filtered)\", df.shape[0])\n",
    "    return df\n",
    "\n",
    "def plot_in_out_degree_dist(G):\n",
    "    in_degrees = [G.in_degree(n) for n in G.nodes()]\n",
    "    out_degrees = [G.out_degree(n) for n in G.nodes()]\n",
    "\n",
    "    # Plot histogram with transparency and separate colors\n",
    "    plt.hist(in_degrees, bins=np.arange(0, max(in_degrees + out_degrees) + 2) - 0.5,\n",
    "             alpha=0.6, color='blue', label='In-Degree')\n",
    "    plt.hist(out_degrees, bins=np.arange(0, max(in_degrees + out_degrees) + 2) - 0.5,\n",
    "             alpha=0.6, color='orange', label='Out-Degree')\n",
    "\n",
    "    # Set x and y ticks (optional: customize based on actual data)\n",
    "    plt.xticks(np.arange(0, max(in_degrees + out_degrees) + 1, 5))\n",
    "    plt.yticks(np.arange(0, plt.gca().get_ylim()[1]+1, 5))\n",
    "\n",
    "    plt.xlabel(\"Degree\")\n",
    "    plt.ylabel(\"Number of Nodes\")\n",
    "    plt.title(\"In-Degree and Out-Degree Distribution\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"plots/node_degree_distr_{cluster_of_interest}_{target_gene}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_activation_score_distribution(df, target_gene, cluster_of_interest):\n",
    "    print(df.head(10))\n",
    "    col_name = \"Correlation\"\n",
    "    subset_df = df[df['edge'].str.contains(target_gene)]\n",
    "    plt.figure(figsize=(8,6))\n",
    "    subset_df[col_name].hist(bins=20, color='skyblue', edgecolor='black')\n",
    "    plt.xlabel('Activation Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.title(f\"Activation score distribution cluster {cluster_of_interest}: {target_gene}\")\n",
    "    plt.savefig(f\"plots/act_score_{cluster_of_interest}_{target_gene}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"Activation score distribution fig saved.\")\n",
    "\n",
    "def build_graph(df, threshold, focus_genes=None):\n",
    "    G = nx.DiGraph()\n",
    "    col_name = \"Correlation\"\n",
    "\n",
    "    if focus_genes:\n",
    "        for _, row in df.iterrows():\n",
    "            target, tf = row['edge'].split(\"->\")  # Swap order here\n",
    "            if tf in focus_genes and target in focus_genes:\n",
    "                if target == tf:\n",
    "                    continue\n",
    "                score = row[col_name]\n",
    "                G.add_edge(tf, target, weight=score, label=f\"{score:.2f}\")\n",
    "    else:\n",
    "        for _, row in df.iterrows():\n",
    "            target, tf = row['edge'].split(\"->\")  # Swap order here\n",
    "            score = row[col_name]\n",
    "            G.add_edge(tf, target, weight=score, label=f\"{score:.2f}\")\n",
    "\n",
    "    hub_nodes = [n for n in G.nodes if G.out_degree(n) >= threshold]\n",
    "    filtered_edges = [(u, v, G[u][v]) for u, v in G.edges if u in hub_nodes]\n",
    "\n",
    "    final_G = nx.DiGraph()\n",
    "    final_G.add_edges_from([(u, v, d) for u, v, d in filtered_edges])\n",
    "    return final_G\n",
    "\n",
    "\n",
    "def map_genes(G):\n",
    "    #if you're species of interest doesnt have a full annotation, you can you an excel sheet with gene_id, predicted_gene_sybmol to annotate you plot\n",
    "    gene_names = {node: node.split(\".\")[-1] for node in G.nodes}\n",
    "    subgraph_gene_names = {node: gene_names[node] for node in G.nodes if node in gene_names}\n",
    "\n",
    "    # Load ortholog translation table\n",
    "    translation_df = pd.read_excel(\"gene_symbol_annotation.xlsx\")\n",
    "    translation_dict = dict(zip(translation_df['Gene ID'], translation_df['Gene Symbol']))\n",
    "\n",
    "    # Handle missing values\n",
    "    for k, v in translation_dict.items():\n",
    "        if pd.isna(v):\n",
    "            translation_dict[k] = k\n",
    "    node_ortholog_dict = {}\n",
    "    for node, gene_name in subgraph_gene_names.items():\n",
    "        node_ortholog_dict[node] = translation_dict.get(node, gene_name)\n",
    "    return node_ortholog_dict\n",
    "def plot_graph(G, node_ortholog_dict, cluster_of_interest, target_gene=None, save_fig=None):\n",
    "    if len(G.nodes) == 0:\n",
    "        print(\"No nodes to plot.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    pos = nx.spring_layout(G)\n",
    "\n",
    "    source_nodes = {u for u, v in G.out_edges()}\n",
    "    sink_nodes = set(G.nodes) - source_nodes\n",
    "    edges = G.edges()\n",
    "\n",
    "    weights = [G[u][v]['weight'] for u, v in edges]\n",
    "    norm = colors.Normalize(vmin=0, vmax=1)\n",
    "    cmap = plt.cm.coolwarm\n",
    "\n",
    "    nx.draw_networkx_nodes(\n",
    "        G, pos,\n",
    "        nodelist=source_nodes,\n",
    "        node_size=600,\n",
    "        node_color=\"#4c6ef5\"\n",
    "    )\n",
    "    nx.draw_networkx_nodes(\n",
    "        G, pos,\n",
    "        nodelist=sink_nodes,\n",
    "        node_size=200,\n",
    "        node_color=\"#f6a800\"\n",
    "    )\n",
    "    nx.draw_networkx_labels(G, pos, labels=node_ortholog_dict, font_size=10)\n",
    "\n",
    "    nx.draw_networkx_edges(\n",
    "        G, pos, edgelist=edges,\n",
    "        edge_color=weights,\n",
    "        edge_cmap=cmap,\n",
    "        edge_vmin=0, edge_vmax=1,\n",
    "        width=1,\n",
    "        arrows=True,\n",
    "        arrowsize=10,\n",
    "        arrowstyle='-|>'\n",
    "    )\n",
    "    # Add colorbar (legend for edge weights)\n",
    "    sm = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])  # Workaround to satisfy colorbar requirement\n",
    "    cbar = plt.colorbar(sm, ax=plt.gca(), shrink=0.6)\n",
    "    cbar.set_label(\"Predicted polarity score\", fontsize=10)\n",
    "    cbar.ax.tick_params(labelsize=10)\n",
    "\n",
    "    # Remove edge labels\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels={}, font_size=10)\n",
    "\n",
    "    if target_gene:\n",
    "        if save_fig:\n",
    "            filename = f\"plots/interaction_graph_{cluster_of_interest}_{save_fig}.png\"\n",
    "        else:\n",
    "            filename = f\"plots/interaction_graph_{cluster_of_interest}_{target_gene}.png\"\n",
    "    else:\n",
    "        filename = f\"plots/interaction_graph_{cluster_of_interest}_full.png\"\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved graph to {filename}\")\n",
    "\n",
    "\n",
    "# === RUNNING SECTION ===\n",
    "\n",
    "cluster_of_interest = \"all\"\n",
    "threshold = 1\n",
    "\n",
    "if target_genes:\n",
    "    # Keep only edges where BOTH source and target are in target_genes\n",
    "    df[['source', 'target']] = df['edge'].str.split('->', expand=True)\n",
    "    df_filtered = df[df['source'].isin(target_genes) & df['target'].isin(target_genes)]\n",
    "    df_filtered = df_filtered.head(n_rows)\n",
    "    print(\"number of edges (between target genes only):\", df_filtered.shape[0])\n",
    "    G = build_graph(df_filtered, threshold=threshold, focus_genes=target_genes)\n",
    "    target_gene = \"_\".join(target_genes)  # For plot label\n",
    "else:\n",
    "    df = df.head(n_rows)\n",
    "    G = build_graph(df, threshold=threshold)\n",
    "\n",
    "\n",
    "#if you're species of interest doesnt have a full annotation, you can you an \n",
    "# excel sheet with gene_id, predicted_gene_sybmol to annotate you plot\n",
    "# otherwise, the map_genes funciton is not necessary\n",
    "node_ortholog_dict = map_genes(G)\n",
    "title = \"sc-grip_plot\"\n",
    "\n",
    "\n",
    "plot_graph(G, node_ortholog_dict, cluster_of_interest, target_gene=target_gene,save_fig = title)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
